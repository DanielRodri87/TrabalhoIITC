# üì¶ Importa√ß√£o das Bibliotecas  

Nesta etapa inicial, s√£o importadas todas as bibliotecas necess√°rias para o **pr√©-processamento de dados, an√°lise estat√≠stica, visualiza√ß√£o gr√°fica e modelagem preditiva**.  

---

## üîß Principais bibliotecas utilizadas  

- **Manipula√ß√£o e an√°lise de dados**  
  - `numpy` ‚Üí Opera√ß√µes matem√°ticas e vetoriais  
  - `pandas` ‚Üí Estrutura√ß√£o e manipula√ß√£o de *datasets*  

- **Visualiza√ß√£o de dados**  
  - `matplotlib.pyplot` ‚Üí Gr√°ficos b√°sicos e personaliz√°veis  
  - `seaborn` ‚Üí Visualiza√ß√µes estat√≠sticas com estilo aprimorado  

- **Pr√©-processamento**  
  - `StandardScaler` ‚Üí Normaliza√ß√£o dos dados  
  - `LabelEncoder` ‚Üí Codifica√ß√£o de vari√°veis categ√≥ricas  

- **Redu√ß√£o de dimensionalidade**  
  - `PCA` (*Principal Component Analysis*) ‚Üí Extra√ß√£o de componentes principais  

- **Sele√ß√£o de caracter√≠sticas**  
  - `RFE` (*Recursive Feature Elimination*) ‚Üí Sele√ß√£o de atributos relevantes  

- **Modelos de aprendizado de m√°quina**  
  - `LogisticRegression` ‚Üí Classifica√ß√£o linear  
  - `Lasso` ‚Üí Regress√£o com regulariza√ß√£o L1  
  - `RandomForestClassifier` ‚Üí Modelo de ensemble baseado em √°rvores de decis√£o  

- **Valida√ß√£o e m√©tricas**  
  - `train_test_split`, `cross_val_score` ‚Üí Divis√£o de dados e valida√ß√£o cruzada  
  - `accuracy_score`, `classification_report` ‚Üí Avalia√ß√£o de desempenho  

- **Outros recursos**  
  - `warnings` ‚Üí Controle de mensagens de alerta  

---

## üé® Configura√ß√µes de visualiza√ß√£o  

- Tamanho padr√£o das figuras ajustado para **12x8**  
- Estilo gr√°fico definido como `default`  
- Paleta de cores `husl` aplicada no Seaborn  

---

‚úÖ **Mensagem de verifica√ß√£o**:  
```python
print("Bibliotecas importadas com sucesso!")

## üìÇ Carregamento dos Dados

Nesta c√©lula, os caminhos do **dataset** s√£o definidos e os arquivos s√£o carregados do Google Drive.  
Foram utilizados os seguintes arquivos:  

- `X_train.txt` ‚Üí atributos de treino  
- `y_train.txt` ‚Üí r√≥tulos de treino  
- `X_test.txt` ‚Üí atributos de teste  
- `y_test.txt` ‚Üí r√≥tulos de teste  
- `features.txt` ‚Üí nomes das vari√°veis  
- `activity_labels.txt` ‚Üí mapeamento das atividades  

Ao final, s√£o exibidos os **shapes** de cada conjunto para confirmar o carregamento correto.  


## üîÑ Combina√ß√£o e Identifica√ß√£o dos Dados

Nesta etapa:  
- Foram **unidos** os conjuntos de treino e teste em `X` (atributos) e `y` (r√≥tulos).  
- As colunas de `X` receberam nomes gen√©ricos (`feature_0`, `feature_1`, ...).  
- O vetor `y` ganhou o mapeamento das atividades para nomes descritivos:
  - WALKING  
  - WALKING_UPSTAIRS  
  - WALKING_DOWNSTAIRS  
  - SITTING  
  - STANDING  
  - LAYING  

Tamb√©m foram exibidas informa√ß√µes gerais:  
- N√∫mero total de amostras  
- N√∫mero de atributos  
- N√∫mero de classes distintas  
- Distribui√ß√£o de amostras por classe  

Por fim, foi feita a **verifica√ß√£o de valores faltantes** em `X` e `y`.  


## ‚öôÔ∏è Pr√©-processamento dos Dados

Nesta etapa:  
- Foram separados os **atributos (`X_data`)** e os **r√≥tulos (`y_data`)**.  
- Aplicou-se a **normaliza√ß√£o com StandardScaler**, fundamental para m√©todos como PCA.  

Resultados exibidos:  
- M√©dia e desvio padr√£o antes da normaliza√ß√£o.  
- M√©dia e desvio padr√£o ap√≥s normaliza√ß√£o (esperados ‚âà 0 e ‚âà 1).  
- Estat√≠sticas de algumas features para verificar a padroniza√ß√£o.  


## üìä PCA com 2 Componentes

Nesta etapa foi aplicado o **PCA (Principal Component Analysis)** para reduzir os dados a **2 componentes principais**.  

Informa√ß√µes exibidas:  
- Vari√¢ncia explicada por cada componente (PC1 e PC2).  
- Vari√¢ncia total explicada pelos dois componentes.  

Tamb√©m foi gerado um **gr√°fico de dispers√£o em 2D**, onde:  
- Cada ponto representa uma amostra do dataset.  
- As cores diferenciam as atividades (`WALKING`, `SITTING`, `STANDING`, etc.).  
- Os eixos PC1 e PC2 indicam a propor√ß√£o de vari√¢ncia capturada.  


## üìà PCA com Todos os Componentes

Nesta etapa, o **PCA foi aplicado sem restri√ß√£o do n√∫mero de componentes**, permitindo analisar a contribui√ß√£o de cada um deles.  

### üîé Objetivos
- Calcular a **vari√¢ncia explicada individualmente** por cada componente.  
- Obter a **vari√¢ncia acumulada**, que indica a propor√ß√£o total de informa√ß√£o retida √† medida que novos componentes s√£o adicionados.  
- Determinar o n√∫mero m√≠nimo de componentes necess√°rios para reter **90% da vari√¢ncia**.  

### ‚úÖ Resultados
- O n√∫mero de componentes necess√°rio para atingir 90% da vari√¢ncia foi identificado (`n_components_90`).  
- A vari√¢ncia acumulada correspondente foi exibida.  

### üìä Visualiza√ß√£o
Foram constru√≠dos dois gr√°ficos complementares (*scree plots*):  
1. **Vari√¢ncia explicada individual** pelos primeiros 50 componentes.  
2. **Vari√¢ncia acumulada** at√© 100 componentes, destacando a linha de corte de 90% e o ponto exato onde ela √© alcan√ßada.  

Essas visualiza√ß√µes permitem observar:  
- Quais componentes carregam mais informa√ß√£o.  
- Em que ponto adicionar novos componentes deixa de trazer ganhos significativos.  


## üîç RFE - Recursive Feature Elimination (Simplificado)

Nesta etapa foi aplicada a t√©cnica de **RFE (Recursive Feature Elimination)** para sele√ß√£o de atributos mais relevantes.  

### ‚úîÔ∏è Procedimentos
- Divis√£o dos dados em treino (80%) e teste (20%) com estratifica√ß√£o.  
- Classificadores utilizados:  
  - **Logistic Regression**  
  - **Random Forest** (vers√£o leve, `n_estimators=20`)  
- Testados diferentes n√∫meros de atributos selecionados: **10, 30 e 50**.  
- Acur√°cias obtidas para cada caso foram registradas e comparadas em gr√°fico.  

### üìä Resultados
- O gr√°fico mostra a rela√ß√£o entre **n√∫mero de features** e **acur√°cia** para cada classificador.  
- Tamb√©m foram identificadas as **features mais relevantes** usando **Random Forest + RFE (30 atributos)**.  

Esse processo ajuda a verificar se √© poss√≠vel manter boa performance do modelo com um conjunto reduzido de vari√°veis.  


## üèπ Lasso - Regulariza√ß√£o L1

Nesta etapa foi aplicada a **regulariza√ß√£o L1 (Lasso)** usando `LogisticRegression` para o problema multiclasse.  

### ‚úîÔ∏è Procedimentos
- Testados diferentes valores de **C** (inverso da regulariza√ß√£o): `0.001, 0.01, 0.1, 1, 10`.  
- Para cada valor de C foram avaliados:  
  - **Acur√°cia** no conjunto de teste.  
  - **N√∫mero de features n√£o-zero** (selecionadas pelo Lasso).  
- Identificado o **melhor valor de C** com base na maior acur√°cia.  

### üìä Resultados exibidos
1. **N√∫mero de features n√£o-zero vs C** ‚Üí mostra como o n√≠vel de regulariza√ß√£o afeta a sele√ß√£o.  
2. **Acur√°cia vs C** ‚Üí permite observar a performance em rela√ß√£o √† for√ßa da penaliza√ß√£o.  
3. **Coeficientes n√£o-zero do melhor modelo** ‚Üí destaca quais atributos foram mantidos.  

### ‚úÖ Conclus√£o
- O melhor valor de **C** foi exibido, junto com sua acur√°cia e n√∫mero de features selecionadas.  
- Tamb√©m foi listada a quantidade total de atributos escolhidos e os √≠ndices das **primeiras 20 features relevantes**.  


## üîÑ Compara√ß√£o RFE vs Lasso

Nesta etapa, comparamos os atributos selecionados pelos dois m√©todos de **sele√ß√£o de features**:  
- **RFE (Recursive Feature Elimination)**  
- **Lasso (Regulariza√ß√£o L1)**  

### ‚úîÔ∏è M√©tricas calculadas
- N√∫mero total de features selecionadas por cada m√©todo.  
- N√∫mero de features em comum.  
- Features √∫nicas de cada m√©todo.  
- Percentual de sobreposi√ß√£o entre RFE e Lasso.  

### üìä Visualiza√ß√µes
1. **Diagrama de Venn aproximado** ‚Üí mostra graficamente as features √∫nicas e comuns.  
2. **Gr√°fico de barras comparativo** ‚Üí quantifica o n√∫mero de features selecionadas por cada m√©todo e as compartilhadas.  

Essas an√°lises ajudam a entender **semelhan√ßas e diferen√ßas na sele√ß√£o de atributos**, indicando quais vari√°veis s√£o mais consistentes entre m√©todos.  


## üîé An√°lise de Padr√µes e Tend√™ncias

### 1Ô∏è‚É£ Separabilidade no PCA
- Apenas 2 componentes explicam **~{total_variance_2d*100:.2f}%** da vari√¢ncia total.  
- Atividades est√°ticas (SITTING, STANDING, LAYING) tendem a se agrupar.  
- Atividades din√¢micas (WALKING variants) formam clusters distintos.  
- Sobreposi√ß√£o entre algumas classes indica que **2 componentes n√£o s√£o suficientes** para separa√ß√£o completa.

### 2Ô∏è‚É£ Compara√ß√£o RFE vs Lasso
- **Taxa de concord√¢ncia**: {overlap_ratio*100:.1f}%  
- Alta concord√¢ncia ‚Üí m√©todos identificam features similares.  
- M√©dia/baixa concord√¢ncia ‚Üí diferen√ßas importantes entre os m√©todos.

### 3Ô∏è‚É£ Benef√≠cios e limita√ß√µes dos m√©todos
**PCA:**  
+ Reduz dimensionalidade e preserva vari√¢ncia  
- Perde interpretabilidade  

**RFE:**  
+ Mant√©m interpretabilidade, considera import√¢ncia para classifica√ß√£o  
- Computacionalmente mais caro, depende do classificador base  

**Lasso:**  
+ Sele√ß√£o autom√°tica, previne overfitting, eficiente  
- Pode remover features correlacionadas, sens√≠vel √† escala dos dados

---

## üèÅ Resumo Final dos Resultados

**Dataset UCI HAR:**  
- Amostras: {n_samples}  
- Features: {n_features}  
- Classes: {n_classes}  

**PCA:**  
- 2 componentes explicam ~{total_variance_2d*100:.2f}% da vari√¢ncia  
- Para 90% da vari√¢ncia: {n_components_90} componentes  

**RFE (Random Forest):**  
- Melhor performance com ~100-150 features  
- Features selecionadas: {len(selected_features_rfe)}  

**Lasso:**  
- Melhor C: {best_C}  
- Features selecionadas: {len(features_selected_lasso)}  
- Acur√°cia: {best_lasso['accuracy']:.4f}  

**Compara√ß√£o RFE vs Lasso:**  
- Features em comum: {len(common_features)}  
- Taxa de concord√¢ncia: {overlap_ratio*100:.1f}%  

**Conclus√£o:**  
- O dataset UCI HAR possui alta dimensionalidade que pode ser reduzida eficazmente.  
- PCA √© ideal para visualiza√ß√£o; RFE e Lasso preservam interpretabilidade e performance de classifica√ß√£o.  
- A escolha do m√©todo depende do objetivo: visualiza√ß√£o (PCA) vs interpretabilidade e classifica√ß√£o (RFE/Lasso).

---

### üíæ Resultados Salvos
Os principais resultados foram armazenados em `results_summary` para futuras an√°lises ou relat√≥rios.




